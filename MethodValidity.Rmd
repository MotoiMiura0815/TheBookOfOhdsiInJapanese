# --翻訳作業中--　方法の妥当性 {#MethodValidity}

\index{方法の妥当性}

*章リード: Martijn Schuemie*

方法の妥当性を検討する際には、次の質問に答えることを目的とします。

> この方法はこの質問に答えるために妥当ですか？

「方法」には研究デザインだけでなく、データやデザインの実施も含まれます。したがって、方法の妥当性は、ある意味で包括的なものです。 データ品質、臨床的妥当性、ソフトウェアの妥当性が良好でなければ、方法の妥当性を十分に観察することはできない場合がよくあります。 方法の妥当性を検討する前に、エビデンスの品質に関するこれらの側面はすでに個別に検討されているはずです。

方法の妥当性を確立する上での中心的な活動は、分析における重要な仮定が満たされているかどうかを評価することです。例えば、傾向スコアマッチングによって2つの母集団を比較可能になるという前提を立てますが、それが事実であるかどうかを評価する必要があります。可能な場合には、これらの前提を検証するための実証的テストを実施すべきです。例えば、マッチング後の2つの母集団が、幅広い特性において実際に比較可能であることを示す診断を生成することができます。OHDSIでは、分析が実施されるたびに生成および評価されるべき、多くの標準診断を開発しました。

本章では、集団レベルの推定で使用される手法の妥当性に焦点を当てます。まず、研究デザインに特化した診断法を簡単に説明し、次に、集団レベルの推定研究のすべてではないにしても、ほとんどに適用できる診断法について説明します。最後に、OHDSIツールを使用してこれらの診断法を実行する方法を段階的に説明します。本章の締めくくりとして、OHDSI Methods BenchmarkとOHDSI Methods Libraryへの応用について、高度なトピックを紹介します。

## デザイン特有の診断

\index{研究診断}

各研究デザインには、そのデザインに特有の診断法があります。これらの診断法の多くは、[OHDSI Methods Library](https://ohdsi.github.io/MethodsLibrary/)のRパッケージで実装されており、すぐに利用できます。例えば、[12.9](https://ohdsi.github.io/TheBookOfOhdsi/PopulationLevelEstimation.html#studyOutputs)項では、[CohortMethod](https://ohdsi.github.io/CohortMethod/)パッケージで生成される幅広い診断法がリストアップされており、以下が含まれます。

-   コホートの初期の比較可能性を評価するための**傾向スコア分布**。

-   モデルから除外すべき潜在変数を特定するための**傾向モデル**。

-   傾向スコア調整によりコホートが比較可能になったかどうかを評価するための**共変量バランス**（ベースライン共変量で測定）。

-   さまざまな分析ステップで除外された対象者の数を観察するための**脱落**。これは、関心のある初期コホートに対する結果の一般化可能性について情報を提供する可能性がある。

-   質問に答えるのに十分なデータが利用可能かどうかを評価するための**検出力**。

-   典型的な発症までの時間を評価し、Cox モデルの基礎となる比例性の仮定が満たされているかどうかを評価するための**Kaplan Meier 曲線**。

他の研究デザインでは、それらのデザインにおける異なる仮説を検証するために、異なる診断が必要となります。例えば、自己制御症例シリーズ（SCCS）デザインでは、観察の終了が結果に依存しないという必要な仮定を確認することができます。この仮定は、心筋梗塞などの深刻で致死の可能性もある事象の場合には、しばしば破られる。この仮定が成り立つかどうかは、図[18.1](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:timeToObsEnd)に示すプロットを生成することで評価できる。このプロットは、打ち切りとなったもの、ならびに打ち切りとならなかったものの観察期間終了までの時間をヒストグラムで示している。我々のデータでは、データ収集の最終日（データベース全体で観察が停止した日、例えば抽出日や研究終了日）に観察期間が終了したものを打ち切りなしとし、それ以外を打ち切りありとみなします。図[18.1](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:timeToObsEnd)では、2つの分布の間にわずかな違いしか見られず、我々の仮説が正しいことが示唆されています。

```{r timeToObsEnd, fig.cap='検閲された被験者とされなかった被験者の観察終了までの時間。',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/timeToObsEnd.png")
```

## 推定のための診断

デザイン固有の診断に加え、因果効果推定法全般に適用できる診断もいくつかあります。これらの多くは、すでに答えがわかっている研究上の仮説であるコントロール仮説の使用に依存しています。コントロール仮説を使用することで、デザインが真実と一致した結果を生み出しているかどうかを評価することができます。コントロールは、ネガティブコントロールとポジティブコントロールに分けることができます。

### ネガティブコントロール {#NegativeControls}

\index{ネガティブコントロール}

ネガティブコントロールとは、因果関係が存在しないと考えられる曝露と結果の組み合わせであり、交絡、選択バイアス、測定エラーを検出する方法として推奨されているネガティブコントロールまたは「偽陰性エンドポイント」（Prasad and Jena [2013年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-prased_2013)）が含まれます。（Lipsitch, Tchetgen Tchetgen, and Cohen [2010年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-lipsitch_2010)） (Arnold et al. [2016](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-arnold_2016)) たとえば、小児期の疾患と後の多発性硬化症（MS）との関係を調査したある研究（Zaadstra et al. [2008](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-zaadstra_2008)）では、著者はMSの原因とは考えられていない3つのネガティブコントロール（腕の骨折、脳震盪、扁桃摘出）を含めている。この3つのコントロールのうち2つはMSと統計的に有意な関連性を示しており、この研究にはバイアスがかかっている可能性を示唆している。

我々は、関心のある仮説と比較可能なネガティブコントロールを選択すべきであり、通常は、関心のある仮説と同じ曝露を持つ曝露-結果の組み合わせ（いわゆる「結果コントロール」）または同じ結果を持つ曝露-結果の組み合わせ（「曝露コントロール」）を選択します。ネガティブコントロールは、さらに以下の基準を満たすべきです。

-   曝露が結果を引き起こす**べきではない**。因果関係を考える一つの方法は、仮説を否定するものを考えることである。患者が曝露されなかった場合と曝露された場合とを比較して、結果が引き起こされる（または防止される）可能性があるだろうか？ 時には、これは明らかである。例えば、ACE阻害薬は血管浮腫を引き起こすことが知られている。しかし、時には、これははるかに明白ではない。例えば、高血圧を引き起こす可能性のある薬物は、間接的に高血圧の結果である心血管疾患を引き起こす可能性がある。

-   曝露はまた、結果を**予防または治療**すべきではありません。これは、真の効果量（例えばハザード比）が1であると考えるのであれば、存在しないはずの因果関係です。

-   ネガティブコントロールは**データ内に存在**すべきであり、理想的には十分な数であるべきです。この目的を達成するために、有病率に基づいてネガティブコントロールの候補を優先付けします。

-   ネガティブコントロールは理想的には**独立している**べきです。例えば、ネガティブコントロールが互いに祖先（例えば、「巻き爪」と「足の巻き爪」）であったり、兄弟（例えば、「左大腿骨の骨折」と「右大腿骨の骨折」）であったりすることは避けるべきです。

-   ネガティブコントロールは、**ある程度の偏りの可能性**があることが理想的です。例えば、社会保障番号の最後の数字は基本的にランダムな数字であり、交絡を示す可能性は低いでしょう。したがって、ネガティブコントロールとして使用すべきではありません。

また、ネガティブコントロールは、注目する曝露と結果のペアと同じ交絡構造を持つべきであるという意見もあります。（Lipsitch, Tchetgen Tchetgen, and Cohen [2010年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-lipsitch_2010)）しかし、この交絡構造は不明であると私たちは考えています。現実に見られる変数間の関係は、人々が想像するよりもはるかに複雑であることがよくあります。また、交絡因子の構造が分かっていたとしても、その交絡因子とまったく同じ構造を持ち、かつ直接的な因果効果を持たないネガティブコントロールが存在する可能性は低いでしょう。このため、OHDSIでは、多数のネガティブコントロールに頼っています。このようなセットは、関心のある仮説に存在するものも含め、多くの異なるタイプのバイアスを表していると想定しているためです。

曝露と結果の間に因果関係がないことは、ほとんど文書化されていません。その代わり、関係性の証拠がないことは関係性がないことを意味するという仮定がしばしばなされます。曝露と結果の両方が広範囲に研究されている場合、この仮定はより妥当性が高くなります。例えば、全く新しい薬物に対する証拠がないことは、関係性がないことを意味するのではなく、知識がないことを意味する可能性が高いです。この原則を念頭に、私たちはネガティブコントロールを選択するための半自動化された手順を開発しました。（Voss et al. [2016年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-voss_2016)）簡単に説明すると、文献、製品ラベル、および自発報告から得られた情報は自動的に抽出され、統合されてネガティブコントロールの候補リストが作成されます。このリストはその後、自動抽出が正確であったことを確認するためだけでなく、生物学的妥当性などの追加の基準を課すためにも、手動でレビューする必要があります。

### ポジティブコントロール {#PositiveControls}

\index{ポジティブコントロール}

真の相対リスクが1より小さい場合、または1より大きい場合の方法の挙動を理解するには、帰無仮説が真実ではないと考えられるポジティブコントロールを使用する必要があります。残念ながら、観察研究における実際のポジティブコントロールには、3つの理由から問題が生じがちです。第一に、ほとんどの研究状況では、例えば2つの治療効果を比較する場合など、その特定の状況に該当するポジティブコントロールが不足しています。第二に、ポジティブコントロールが利用可能であったとしても、効果の大きさが正確にわからないことがあり、また、多くの場合、測定対象の母集団に依存します。第三に、治療が特定の結果を引き起こすことが広く知られている場合、例えば望ましくない結果のリスクを軽減するための措置が取られるなど、その治療を処方する医師の行動に影響を与え、その結果、評価手段としてのポジティブコントロールが役に立たなくなることがあります。（Noren et al. [2014年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-noren_2014)）

そのため、OHDSIでは合成陽性対照（Schuemie, Hripcsak, et al. [2018](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-schuemie_2018)）を使用しています。これは、曝露のリスクにさらされる期間中に、結果の追加のシミュレーション発生を注入することで、ネガティブコントロールを修正して作成されます。例えば、ACEiへの曝露中に、ネガティブコントロールのアウトカム「陥入爪」がn回発生したと仮定します。曝露中にさらにn回のシミュレーション発生を追加すると、リスクは2倍になります。これはネガティブコントロールであるため、対照群と比較した相対リスクは1ですが、注入後は2になります。

重要な問題として、交絡因子の保存が挙げられます。ネガティブコントロールでは強い交絡が示されるかもしれませんが、ランダムに追加の結果を注入すれば、これらの新しい結果は交絡されません。したがって、ポジティブコントロールの交絡に対処する能力の評価については楽観的になることができます。交絡を保存するには、新しい結果が元の結果と同様のベースライン被験者固有の共変量との関連性を示すことが望まれます。これを達成するために、各アウトカムについて、曝露前に取得した共変量を使用して曝露中のアウトカムに関する生存率を予測するモデルを訓練する。これらの共変量には、人口統計学的データ、およびすべての記録された診断、薬物曝露、測定値、および医療処置が含まれる。正則化超パラメータを選択するために10分割交差検証を使用するL1正則化ポアソン回帰（Suchard et al. [2013](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-suchard_2013)）により、予測モデルを適合させる。次に、曝露中のシミュレーション結果を予測率を用いてサンプリングし、真の効果の大きさを望ましい大きさにまで増大させます。その結果、ポジティブコントロールには、実際の結果とシミュレーション結果の両方が含まれます。

図[18.2](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:posControlSynth)は、このプロセスを示しています。この手順では、いくつかの重要なバイアスの原因をシミュレーションしますが、すべてを捕捉するわけではありません。例えば、測定エラーの影響の一部は存在しません。合成ポジティブコントロールは、一定の陽性適中率と感度を意味しますが、現実には必ずしもそうではない場合があります。

```{r posControlSynth, fig.cap='ネガティブコントロールからのポジティブコントロールの合成',echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/posControlSynth.png")
```

各対照について、単一の真の「効果の大きさ」を参照しているが、異なる手法では治療効果の異なる統計値を推定する。因果効果がないと考えるネガティブ対照では、相対リスク、ハザード比、オッズ比、罹患率比（条件付きおよび限界）、平均治療効果（ATT）および全体平均治療効果（ATE）など、すべての統計値は1と同一となる。ポジティブコントロールを作成するプロセスでは、限界効果が達成される時点まで、この比率が一定に保たれる患者を条件としたモデルを使用し、時間経過や患者間の一定の発生率比で結果を統合します。したがって、真の効果量は、処置群における限界発生率比として保持されることが保証されます。合成に使用される成果モデルが正しいという前提の下では、これは条件付き効果量および ATE にも当てはまります。すべての成果はまれであるため、オッズ比は相対リスクとほぼ同一です。

### 実証的評価 {#metrics}

\index{実証的評価}

負のコントロールと正のコントロールに対する特定の手法の推定値に基づき、さまざまな指標を計算することで、その運用特性を理解することができます。例えば、

-   **レシーバーオペレーター曲線下面積（AUC）**：正のコントロールと負のコントロールを識別する能力。

-   **カバー率**：真の効果量が95%信頼区間内に収まる頻度。

-   **平均精度**：精度は1/(標準誤差)2として計算され、精度が高いほど信頼区間が狭くなる。精度の歪んだ分布を考慮するために幾何平均を使用します。

-   **平均二乗誤差（MSE）**：効果量の推定値の対数と真の効果量の対数との間の平均二乗誤差。

-   **第1種の過誤**：負のコントロールの場合、帰無仮説が棄却された頻度（α=0.05）。これは偽陽性率および1−特異度と同等です。

-   **タイプ2エラー**：陽性対照の場合、どのくらいの頻度で帰無仮説が棄却されなかったか（α=0.05）。これは偽陰性率および1−感度と同等である。

-   **非推定可能**：推定値を算出できなかった対照はいくつあったか？推定値が算出できない理由は様々であり、例えば傾向スコアマッチング後に被験者が残らなかった場合や、結果を持つ被験者が残らなかった場合などである。

ユースケースに応じて、これらの操作特性が目的に適しているかどうかを評価することができます。例えば、シグナル検出を行いたい場合は、第1種の過誤と第2種の過誤を考慮する必要があります。また、α閾値を修正する場合は、代わりにAUCを検査することがあります。

### P値のキャリブレーション

\index{p-value calibration} \index{実証的キャリブレーション}

しばしば、第1種の過誤（α=0.05）は5%よりも大きくなります。言い換えれば、実際には帰無仮説が真であるにもかかわらず、5%よりも高い確率で帰無仮説を棄却してしまう可能性が高いということです。その理由は、p値はランダムエラー、すなわちサンプルサイズが限られていることによるエラーのみを反映しているためです。系統的エラー、例えば交絡によるエラーは反映されていません。OHDSIは、p値を補正して第1種の過誤を名目上回復するためのプロセスを開発しました。（Schuemie et al. [2014年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-schuemie_2014)） ネガティブコントロールの実際の効果推定値から経験的帰無分布を導出します。 これらのネガティブコントロールの推定値は、帰無仮説が真である場合に期待される値を示唆するものであり、経験的帰無分布を推定するためにそれらを使用します。

具体的には、各推定値のサンプリングエラーを考慮に入れ、推定値にガウス確率分布を当てはめる。第i番目のネガティブコントロール薬物とアウトカムの組から推定された対数効果推定値（相対リスク、オッズ比、または発生率比）を\^θで表し、対応する推定標準誤差を\^τで表す。i=1,…,n。θiは真の対数効果量（負の対照では0と仮定）を意味し、βiはi番目の対に関連する真の（ただし未知の）バイアス、すなわち、対照が非常に大きかった場合に研究が対照ihadに対して返すであろう推定値の対数と真の対数効果量の差を意味する。標準的なp値の計算と同様に、θi+βiを平均とし、\^τ2iを標準偏差とする正規分布に従うと仮定します。従来のp値の計算では、βiは常にゼロと仮定されていましたが、我々は、μを平均とし、σ2を分散とする正規分布から生じるβiを仮定します。これは、帰無（バイアス）分布を表します。我々は、最尤法によりμとσ2を推定します。要約すると、我々は以下の仮定を置きます。

$$\beta_i \sim N(\mu,\sigma^2) \text{  そして  } \hat{\theta}_i \sim N(\theta_i + \beta_i, \tau_i^2)$$

ここで $N(a,b)$ は平均値 $a$ 、分散 $b$ のガウス分布を示します。尤度:

$$L(\mu, \sigma | \theta, \tau) \propto \prod_{i=1}^{n}\int p(\hat{\theta}_i|\beta_i, \theta_i, \hat{\tau}_i)p(\beta_i|\mu, \sigma) \text{d}\beta_i$$

ここから最大尤度推定 $\hat{\mu}$ と $\hat{\sigma}$ を得ます。キャリブレートされたp値を実証的な帰無分布を用いて計算します。新しいドラッグ-アウトカムペアの効果推定 $\hat{\theta}_{n+1}$ を取り、対応する推定標準誤差 $\hat{\tau}_{n+1}$ を用います。前述の仮定の下で $\beta_{n+1}$ が同じ帰無分布から発生したとして、次が得られます。

$$\hat{\theta}_{n+1} \sim N(\hat{\mu}, \hat{\sigma} + \hat{\tau}_{n+1})$$

ここでは、$\hat{\theta}_{n+1}$ は $\hat{\mu}$ より小さく、新しいペアのキャリブレーションされた片側P値は、

$$\phi\left(\frac{\theta_{n+1} - \hat{\mu}}{\sqrt{\hat{\sigma}^2 + \hat{\tau}_{n+1}^2}}\right)$$

ここでは $\phi(\cdot)$ は、標準正規分布の累積分布関数を表します。また、$\hat{\theta}_{n+1}$ が $\hat{\mu}$ より大きいとき、キャリブレーションされた片側P値は、

$$1-\phi\left(\frac{\theta_{n+1} - \hat{\mu}}{\sqrt{\hat{\sigma}^2 + \hat{\tau}_{n+1}^2}}\right)$$

### 信頼区間のキャリブレーション

\index{confidence interval calibration}

同様に、通常、95%信頼区間のカバー率は95%未満であることが観察されます。真の効果量は、95%信頼区間内に収まるのは95%未満です。信頼区間キャリブレーション（Schuemie, Hripcsak, et al. [2018年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-schuemie_2018)）では、正のコントロールも活用することで、p値キャリブレーションの枠組みを拡張します。通常、必ずしもそうとは限りませんが、校正された信頼区間は名義尺度の信頼区間よりも広くなり、標準的な手順では考慮されていない問題（未測定の交絡、選択バイアス、測定誤差など）を反映しますが、校正では考慮されます。

厳密には、ベータ（対iに関連するバイアス）は再びガウス分布から得られると仮定しますが、今回は平均と標準偏差が真のエフェクトサイズである$theta_i$と線形関係にあるものを使用します：

$$\beta_i \sim N(\mu(\theta_i) , \sigma^2(\theta_i))$$

ここでは、

$$\mu(\theta_i) = a + b \times \theta_i \text{ and }$$ $$\sigma(\theta_i) ^2= c + d \times \mid \theta_i \mid$$

a$、$b$、$c$、$d$は、未観測の$beta_i\$を積分した限界化尤度を最大化することで推定します：

$$l(a,b,c,d | \theta, \hat{\theta}, \hat{\tau} ) \propto \prod_{i=1}^{n}\int p(\hat{\theta}_i|\beta_i, \theta_i, \hat{\tau}_i)p(\beta_i|a,b,c,d,\theta_i) \text{d}\beta_i ,$$

最尤推定値 $(\hat{a}, ˶{b}, ˶{c}, ˶{d})$.

系統誤差モデルを用いた較正CIを計算します。再び$hat{θ}_{n+1}$を注目する新しい結果に対する効果推定値の対数とし、$hat{tau}_{n+1}$を対応する推定標準誤差とします。上記の仮定から、$beta_{n+1}$が同じ系統誤差モデルから生じると仮定すると、次のようになります：

$$\hat{\theta}_{n+1} \sim N(
\theta_{n+1} + \hat{a} + \hat{b} \times \theta_{n+1},
\hat{c} + \hat{d} \times \mid \theta_{n+1} \mid + \hat{\tau}_{n+1}^2) .$$

この式を$thetheta_{n+1}$について解くことで、較正された95%CIの下界を求めます：

$$\Phi\left(
\frac{\theta_{n+1} + \hat{a} + \hat{b} \times \theta_{n+1}-\hat{\theta}_{n+1}}
{\sqrt{(\hat{c} + \hat{d} \times \mid \theta_{n+1} \mid) + \hat{\tau}_{n+1}^2}}
\right) = 0.025 ,$$

ここで、$Phi( \cdot)$ は標準正規分布の累積分布関数を表します。確率0.975についても同様に上限を求めます。確率0.5を用いて校正点推定値を定義します。

p値較正と信頼区間較正の両方が[EmpiricalCalibration](https://ohdsi.github.io/EmpiricalCalibration/)パッケージで実装されています。

### 医療機関を跨いだ複製

\index{between-database heterogeneity}

別の方法検証の形として、異なる母集団、異なる医療システム、および/または異なるデータ収集プロセスを表す複数の異なるデータベースで研究を実施することが挙げられます。これまでの研究では、異なるデータベースで同じ研究デザインを実施すると、効果量の推定値が大幅に異なることが示されています（Madigan et al. [2013年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-madigan_2013)）。これは、異なる母集団では効果が大幅に異なるか、または異なるデータベースで見られる異なるバイアスを研究デザインが適切に考慮していないことを示唆しています。実際、信頼区間の経験的キャリブレーションによりデータベース内の残差バイアスを考慮することで、研究間の異質性を大幅に低減できることがわかっています。 (Schuemie, Hripcsak, et al. [2018年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-schuemie_2018))

データベース間の異質性を表現する一つの方法として、$I^2$ スコアがあります。これは、偶然ではなく異質性に起因する研究間の総変動の割合を表します。（Higgins et al. [2003年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-higgins_2003)）$I^2$ の値を単純に分類することは、すべての状況に適切であるとはいえませんが、25%、50%、75%の$I^2$ 値にそれぞれ「低」、「中程度」、「高」という形容詞を仮に割り当てることはできます。大規模傾向スコア調整を用いた新規ユーザーコホートデザインを使用して、多くのうつ病治療の効果を推定した研究では、（Schuemie、Ryan、et al. [2018年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-schuemie_2018b)）推定値の58％のみが$I^2$ が25％未満であることが観察された。実証的な較正後、この値は83％に増加した。

```{block2, type='rmdimportant'}
データベース間の異質性を観察すると、推定値の妥当性に疑問が生じます。残念ながら、その逆は真ではありません。異質性を観察しないと、偏りのない推定値が保証されるわけではありません。すべてのデータベースが同様の偏りを共有している可能性は低くなく、したがってすべての推定値が常に誤っている可能性もあります。
```

### 感度分析

\index{sensitivity analysis}

研究を計画する際には、不確実な設計上の選択肢がしばしば存在します。例えば、層化傾向スコアマッチングを使用すべきでしょうか？層化を使用する場合、層をいくつに分けるべきでしょうか？適切なリスクにさらされた期間はどのくらいでしょうか？このような不確実性に直面した場合、解決策の一つは、さまざまな選択肢を評価し、設計上の選択肢に対する結果の感度を観察することです。さまざまな選択肢の下で推定値が同じままであれば、その研究は不確実性に強いと言えるでしょう。

この感度分析の定義は、例えばRosenbaum（[2005年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-rosenbaum_2005)）が「さまざまな規模の隠れた偏りによって研究の結論がどのように変化するかを評価する」と定義している感度分析の定義と混同すべきではありません。

## 実践におけるメソッド検証

ここでは、第[12章](https://ohdsi.github.io/TheBookOfOhdsi/PopulationLevelEstimation.html#PopulationLevelEstimation)の例を基に、ACE阻害薬（ACEi）が血管浮腫および急性心筋梗塞（AMI）のリスクに及ぼす影響について、サイアザイド系およびサイアザイド系利尿薬（THZ）と比較して調査します。その章では、すでに、使用したデザインであるコホート法に特有の診断の多くを調査しています。ここでは、他のデザインが使用されていた場合にも適用されていた可能性のある追加の診断を適用します。セクション[12.7](https://ohdsi.github.io/TheBookOfOhdsi/PopulationLevelEstimation.html#PleAtlas)で説明されているようにATLASを使用して研究が実施された場合、これらの診断はATLASによって生成された研究Rパッケージに含まれるShinyアプリで利用可能です。セクション[12.8](https://ohdsi.github.io/TheBookOfOhdsi/PopulationLevelEstimation.html#pleR)で説明されているように、代わりにRを使用して研究が実施された場合、次のセクションで説明されているように、さまざまなパッケージで利用可能なR関数を使用する必要があります。

### ネガティブコントロールの選択

私たちは、因果効果は存在しないと考えられるネガティブコントロール、すなわち曝露と結果の組み合わせを選択しなければなりません。私たちの例の研究のような比較効果推定では、対象曝露も比較曝露も原因ではないと考えられるネガティブコントロールの結果を選択します。私たちは、コントロールに表れるさまざまなバイアスを確実に反映させ、また実証的な校正を可能にするために、十分な数のネガティブコントロールを必要とします。経験則として、通常は50～100件のネガティブコントロールを目標とします。これらのコントロールは完全に手作業で作成することも可能ですが、幸いにもATLASには文献、製品ラベル、自発報告からのデータを使用してネガティブコントロールを選択する機能が備わっています。

ネガティブコントロールの候補リストを作成するには、まず、関心のある曝露をすべて含む概念セットを作成する必要があります。このケースでは、図[18.3](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:exposuresConceptSet)に示すように、ACEiおよびTHZクラスのすべての成分を選択します。

```{r exposuresConceptSet, fig.cap='ターゲットおよび比較曝露を定義する概念を含むコンセプトセット',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/exposuresConceptSet.png")
```

次に、「エビデンスを探る」タブに移動し、！[ ](images/MethodValidity/generate.png)ボタンをクリックします。エビデンス概要の生成には数分かかりますが、その後、！[ ](images/MethodValidity/viewEvidence.png)ボタンをクリックできます。これにより、図\@ref(fig:candidateNcs)に示されるように、結果のリストが表示されます。

```{r candidateNcs, fig.cap='文献、製品ラベル、および自発的な報告から見つかった証拠の概要を示す候補コントロール結果',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/candidateNcs.png")
```

このリストには、条件の概念と、その条件を弊社が定義した曝露のいずれかと関連付ける証拠の概要が示されます。例えば、さまざまな戦略を使用してPubMedで曝露と結果を関連付ける文献の数、弊社の関心のある曝露の製品ラベルで条件を可能性のある有害作用として記載しているものの数、および自発報告の数を確認できます。デフォルトでは、候補となる陰性対照が最初に表示されるようにリストがソートされます。次に、「ソート順」によってソートされ、これは観察データベースの集合におけるその状態の有病率を表します。ソート順が高いほど、有病率も高くなります。これらのデータベースにおける有病率は、調査を実施したいデータベースにおける有病率と一致しない可能性もありますが、近似値としては妥当であると考えられます。

次のステップは、候補リストを手動で確認することです。通常はリストの上から始め、最も頻度の高い条件から順に確認し、十分であると納得できるまで作業を続けます。この作業を行う一般的な方法としては、リストをCSV（カンマ区切り）ファイルにエクスポートし、セクション[18.2.1](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#NegativeControls)で述べた基準を考慮しながら臨床医に確認してもらいます。

今回の研究例では、付録[C.1](https://ohdsi.github.io/TheBookOfOhdsi/NegativeControlsAppendix.html#AceiThzNsc)にリストされた76のネガティブコントロールを選択します。

### コントロールの仲間

ネガティブコントロールのセットを定義したら、それらを調査に含める必要があります。まず、ネガティブコントロール条件の概念をアウトカムコホートに変換するためのロジックを定義する必要があります。セクション[12.7.3](https://ohdsi.github.io/TheBookOfOhdsi/PopulationLevelEstimation.html#evaluationSettings)では、ATLASがユーザーが選択するいくつかのオプションに基づいて、そのようなコホートを作成する方法について説明しています。多くの場合、単にネガティブコントロール概念またはその子孫のいずれかの出現に基づいてコホートを作成することを選択します。研究が R で実施されている場合、SQL（構造化問い合わせ言語）を使用してネガティブコントロールコホートを構築することができます。第 [9 章](https://ohdsi.github.io/TheBookOfOhdsi/SqlAndR.html#SqlAndR)では、SQL および R を使用してコホートを作成する方法について説明しています。適切な SQL および R を記述する方法については、読者の練習問題とします。

OHDSIツールは、ネガティブコントロールから派生したポジティブコントロールを自動的に生成して含める機能も提供しています。この機能は、セクション[12.7.3](https://ohdsi.github.io/TheBookOfOhdsi/PopulationLevelEstimation.html#evaluationSettings)で説明されているATLASの「評価設定」セクションにあり、[MethodEvaluation](https://ohdsi.github.io/MethodEvaluation/)パッケージの`synthesizePositiveControls`関数に実装されています。ここでは、生存モデルを使用して、真の効果サイズが1.5、2、4の3つのポジティブコントロールを各ネガティブコントロールに対して生成します。

```{r tidy=FALSE,eval=FALSE}
library(MethodEvaluation)
# ターゲット曝露（ACEi = 1）のみを使用して、
# すべてのネガティブコントロール曝露-結果ペアを含むデータフレームを作成
eoPairs <- data.frame(exposureId = 1,
                      outcomeId = ncs)

pcs <- synthesizePositiveControls(
  connectionDetails = connectionDetails,
  cdmDatabaseSchema = cdmDbSchema,
  exposureDatabaseSchema = cohortDbSchema,
  exposureTable = cohortTable,
  outcomeDatabaseSchema = cohortDbSchema,
  outcomeTable = cohortTable,
  outputDatabaseSchema = cohortDbSchema,
  outputTable = cohortTable,
  createOutputTable = FALSE,
  modelType = "survival",
  firstExposureOnly = TRUE,
  firstOutcomeOnly = TRUE,
  removePeopleWithPriorOutcomes = TRUE,
  washoutPeriod = 365,
  riskWindowStart = 1,
  riskWindowEnd = 0,
  endAnchor = "cohort end",
  exposureOutcomePairs = eoPairs,
  effectSizes = c(1.5, 2, 4),
  cdmVersion = cdmVersion,
  workFolder = file.path(outputFolder, "pcSynthesis"))
```

注意すべきは、推定研究の設計で使用されたリスク時間設定を模倣しなければならないということです。`synthesizePositiveControls`関数は、曝露とネガティブコントロールの結果に関する情報を抽出し、曝露と結果の組み合わせごとに結果モデルを適合させ、結果を統合します。ポジティブコントロールの結果コホートは、`cohortDbSchema`および`cohortTable`で指定されたコホートテーブルに追加されます。結果の`pcs`データフレームには、統合されたポジティブコントロールの情報が含まれます。

次に、関心のある効果を推定するために使用したのと同じ研究を実行して、ネガティブコントロールとポジティブコントロールの効果も推定する必要があります。ATLASの比較ダイアログでネガティブコントロールのセットを設定すると、ATLASはこれらのコントロールの推定値を計算するように指示されます。同様に、評価設定でポジティブコントロールを生成するように指定すると、それらも分析に含まれます。Rでは、ネガティブコントロールとポジティブコントロールは、他の結果と同様に処理されます。[OHDSI Methods Library](https://ohdsi.github.io/MethodsLibrary/)のすべての推定パッケージは、多くの効果を効率的に推定することを容易に可能にします。

### 実証されたパフォーマンス

図[18.5](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:controls)は、我々の例の研究に含まれているネガティブコントロールとポジティブコントロールについて、真の効果サイズ別に層別した推定効果サイズを示しています。このプロットは、ATLASによって生成された研究Rパッケージに付属するShinyアプリに含まれており、[MethodEvaluation](https://ohdsi.github.io/MethodEvaluation/)パッケージの`plotControls`関数を使用して生成することができます。コントロールの数は、推定値を生成したりポジティブコントロールを統合したりするのに十分なデータがなかったため、定義された数よりも少ない場合が多いことに注意してください。

```{r controls, fig.cap='ネガティブ（真のハザード比=1）およびポジティブコントロール（真のハザード比> 1）に関する推定値。各点はコントロールを表します。点線の下にある推定値は、真の効果サイズを含まない信頼区間を持ちます。',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/controls.png")
```

これらの推定値をもとに、[MethodEvaluation](https://ohdsi.github.io/MethodEvaluation/)パッケージの`computeMetrics`関数を使用して、表 \@ref(tab:exampleMetrics)に示すメトリクスを計算することができます。

| Metric         | Value |
|:---------------|------:|
| AUC            |  0.96 |
| Coverage       |  0.97 |
| Mean Precision | 19.33 |
| MSE            |  2.08 |
| Type 1 error   |  0.00 |
| Type 2 error   |  0.18 |
| Non-estimable  |  0.08 |

: (#tab:exampleMetrics) ネガティブコントロールとポジティブコントロールの推定値から得られたメソッドのパフォーマンスメトリック

カバレッジとタイプ1エラーは、それぞれ95％と5％という公称値に非常に近く、AUCも非常に高いことがわかります。これは必ずしもそうではありません。

図(ref:fig:controls)では、真のハザード比が1であるとき、すべての信頼区間に1が含まれるわけではありませんが、表(ref:tab:exampleMetrics)の1型誤差は0%であることに注意してください。これは例外的な状況で、[Cyclops](https://ohdsi.github.io/Cyclops/)パッケージの信頼区間が尤度プロファイリングを使って推定されていることが原因です。これは従来の方法よりも正確ですが、信頼区間が非対称になることがあります。代わりにp値は対称信頼区間を仮定して計算され、これが第1種の過誤を計算するために用いられたものです。

図[18.5](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:controls)では、真のハザード比が1である場合の信頼区間すべてに1が含まれていませんが、表[18.1](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#tab:exampleMetrics)の第1種の過誤は0%です。これは例外的な状況であり、[Cyclops](https://ohdsi.github.io/Cyclops/)パッケージの信頼区間が尤度プロファイリングを用いて推定されることによるものです。この方法は従来の方法よりも正確ですが、非対称な信頼区間になる可能性があります。一方、p値は対称な信頼区間を仮定して計算され、これは第1種の過誤を計算する際に使用されたものです。

### P値の較正

負のコントロールの推定値を使用して、p値を調整することができます。これはShinyアプリでは自動的に行われ、Rでは手動で行うことができます。セクション[12.8.6](https://ohdsi.github.io/TheBookOfOhdsi/PopulationLevelEstimation.html#MultipleAnalyses)で説明したように、要約オブジェクト`summ`を作成したと仮定すると、経験的なキャリブレーション効果のプロットを作成することができます。

```{r tidy=FALSE,eval=FALSE}
# Estimates for negative controls (ncs) and outcomes of interest (ois):
ncEstimates <- summ[summ$outcomeId %in% ncs, ]
oiEstimates <- summ[summ$outcomeId %in% ois, ]

library(EmpiricalCalibration)
plotCalibrationEffect(logRrNegatives = ncEstimates$logRr,
                      seLogRrNegatives = ncEstimates$seLogRr,
                      logRrPositives = oiEstimates$logRr,
                      seLogRrPositives = oiEstimates$seLogRr,
                      showCis = TRUE)
```

```{r pValueCal, fig.cap='P-value calibration: estimates below the dashed line have a conventional p < 0.05. Estimates in the shaded area have calibrated p < 0.05. The narrow band around the edge of the shaded area denotes the 95\\% credible interval. Dots indicate negative controls. Diamonds indicate outcomes of interest.',echo=FALSE, out.width='70%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/pValueCal.png")
```

図[18.6](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:pValueCal)では、陰影部分が破線で示された領域とほぼ完全に重なっていることがわかります。これは、陰性対照ではほとんどバイアスが観察されなかったことを示しています。興味のある結果（AMI）の1つは、破線と陰影部分の上にあり、未補正および補正後のp値の両方において帰無仮説を棄却できないことを示しています。もう一方の転帰（血管性浮腫）は、明らかに陰性対照から際立っており、未補正および補正済みのp値がいずれも0.05未満である領域内に収まっています。

補正済みのp値を計算することができます。

```{r tidy=FALSE,eval=FALSE}
null <- fitNull(logRr = ncEstimates$logRr,
                seLogRr = ncEstimates$seLogRr)
calibrateP(null,
           logRr= oiEstimates$logRr,
           seLogRr = oiEstimates$seLogRr)
```

```{r echo=FALSE,message=FALSE,eval=TRUE}
cat("[1] 1.604351e-06 7.159506e-01")
```

そして、較正されていないp値と比較してみましょう。

```{r tidy=FALSE,eval=FALSE}
oiEstimates$p
```

```{r echo=FALSE,message=FALSE,eval=TRUE}
cat("[1] [1] 1.483652e-06 7.052822e-01")
```

予想通り、バイアスはほとんど観察されなかったため、未補正および補正後のp値は非常に類似しています。

### 信頼区間のキャリブレーション

同様に、負のコントロールと正のコントロールの推定値を使用して、信頼区間をキャリブレーションすることができます。Shinyアプリは、キャリブレーションされた信頼区間を自動的に報告します。Rでは、[EmpiricalCalibration](https://ohdsi.github.io/EmpiricalCalibration/)パッケージの`fitSystematicErrorModel`および`calibrateConfidenceInterval`関数を使用して、信頼区間をキャリブレーションすることができます。詳細は、[「信頼区間の経験的キャリブレーション」のヴィネット](https://ohdsi.github.io/EmpiricalCalibration/articles/EmpiricalCiCalibrationVignette.html)を参照してください。

キャリブレーション前の推定ハザード比（95%信頼区間）は、血管性浮腫とAMIでそれぞれ4.32（2.45 - 8.08）と1.13（0.59 - 2.18）です。補正されたハザード比はそれぞれ4.75（2.52 - 9.04）および1.15（0.58 - 2.30）である。

### データベース間の異質性

1つのデータベース（この場合はIBM MarketScan Medicaid (MDCD)データベース）で分析を実施したのと同様に、共通データモデル（CDM）に準拠する他のデータベースでも同じ分析コードを実行することができます。図[18.7](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:forest)は、血管性浮腫の結果について、合計5つのデータベースにわたるフォレストプロットとメタ分析推定値（ランダム効果を仮定）（DerSimonianおよびLaird [1986年](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#ref-dersimonian_1986)）を示しています。この図は、[EvidenceSynthesis](https://ohdsi.github.io/EvidenceSynthesis/)パッケージの`plotMetaAnalysisForest`関数を使用して生成されました。

```{r forest, fig.cap='Effect size estimates and 95\\% confidence intervals (CI) from five different databases and a meta-analytic estimate when comparing ACE inhibitors to thiazides and thiazide-like diuretics for the risk of angioedema.',echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/forest.png")
```

すべての信頼区間が1より大きいため、何らかの影響があるという点では一致していることが示唆されますが、I2はデータベース間の異質性を示唆しています。しかし、図[18.8](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:forestCal)で示したように較正済みの信頼区間を使用してI2を計算すると、この異質性は、ネガティブコントロールとポジティブコントロールを通じて各データベースで測定されたバイアスによって説明できることが分かります。経験的な較正は、このバイアスを適切に考慮しているようです。

```{r forestCal, fig.cap='Calibrated Effect size estimates and 95\\% confidence intervals (CI) from five different databases and a meta-analytic estimate for the hazard ratio of angioedema when comparing ACE inhibitors to thiazides and thiazide-like diuretics.',echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics("images/MethodValidity/forestCal.png")
```

### 感度分析

我々の分析におけるデザインの選択肢のひとつは、傾向スコアで変数比マッチングを使用することだった。しかし、傾向スコアで層別化を使用することも可能だった。この選択肢については不明な点があるため、両方を使用することにした。表[18.2](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#tab:sensAnalysis)は、変数比マッチングと層別化（10の均等サイズの層）を使用した場合のAMIと血管性浮腫に対する効果サイズ推定値を示している（較正ありと較正なしの両方）。

| Outcome | Adjustment | Uncalibrated | Calibrated |
|:---|:---|----|----|
| Angioedema | Matching | 4.32 (2.45 - 8.08) | 4.75 (2.52 - 9.04) |
| Angioedema | Stratification | 4.57 (3.00 - 7.19) | 4.52 (2.85 - 7.19) |
| Acute myocardial infarction | Matching | 1.13 (0.59 - 2.18) | 1.15 (0.58 - 2.30) |
| Acute myocardial infarction | Stratification | 1.43 (1.02 - 2.06) | 1.45 (1.03 - 2.06) |

: 表18.2：2つの分析における補正前および補正後のハザード比（95%信頼区間）

マッチングと層化分析による推定値は、強い一致を示しており、層化分析の信頼区間はマッチングの信頼区間内に完全に収まっています。このことは、この設計選択に関する不確実性は、推定値の妥当性に影響を与えないことを示唆しています。層化はより高い効果量（より狭い信頼区間）をもたらすように見えるが、これは驚くことではない。マッチングではデータの損失が生じるが、層化では生じないためである。ただし、キャリブレーションされた信頼区間にバイアスの増加を示す証拠は見られない。

```{block2, type='rmdimportant'}
研究診断により、研究を完全に実施する前でもデザインの選択肢を評価することができます。すべての研究診断を生成し、確認する前にプロトコルを確定しないことをお勧めします。P-ハッキング（望ましい結果を得るためにデザインを調整すること）を避けるため、これは対象となる効果量の推定値を隠した状態で実施する必要があります。
```

## OHDSIメソッド評価ベンチマーク

\index{OHDSI Methods Benchmark}

推奨される方法は、適用される文脈の中で、その手法のパフォーマンスを経験的に評価することですが、関心のある曝露と結果のペア（例えば、同じ曝露または同じ結果を使用する）と研究で使用されるデータベースに類似したネガティブコントロールとポジティブコントロールを使用して、一般的な手法のパフォーマンスを評価することも価値があります。これが、OHDSI メソッド評価ベンチマークが開発された理由です。このベンチマークは、慢性または急性のアウトカム、長期または短期のエクスポージャーなど、幅広い範囲のコントロール質問を使用してパフォーマンスを評価します。このベンチマークの結果は、メソッドの全体的な有用性を実証するのに役立ち、コンテクスト固有の実証評価が利用できない（または利用できない）場合、メソッドのパフォーマンスに関する事前評価を形成するために使用することができます。このベンチマークは、慎重に選択された200件のネガティブコントロールから構成されており、これらは8つのカテゴリーに層別することができ、各カテゴリーのコントロールは同じエクスポージャーまたは同じ結果を共有している。これらの200件のネガティブコントロールから、セクション[18.2.2](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#PositiveControls)で説明されているように、600件の合成ポジティブコントロールが導かれる。手法を評価するには、すべてのコントロールについて効果量の推定値を生成するためにその手法を使用する必要があり、その後、[18.2.3](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#metrics) 節で説明されている評価基準を計算することができます。ベンチマークは公開されており、[MethodEvaluation](https://ohdsi.github.io/MethodEvaluation/) パッケージの [「OHDSI Methods Benchmark vignette](https://ohdsi.github.io/MethodEvaluation/articles/OhdsiMethodsBenchmark.html)」で説明されているように展開することができます。

私たちは、OHDSI Methods Library に収められているすべての手法をこのベンチマークで実行し、手法ごとにさまざまな分析を選択しました。例えば、コホート法は傾向スコアマッチング、層化、重み付けを用いて評価されました。この実験は、4つの大規模な医療観察データベース上で実行されました。オンラインのShinyアプリで閲覧できる結果^[63](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fn63)^によると、いくつかの手法ではAUC（陽性対照と陰性対照を区別する能力）が高い値を示しているものの、ほとんどの手法ではほとんどの環境において、図[18.9](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:methodEval)に示されているように、第1種の過誤が高く、95%信頼区間のカバー率が低いことが示されています。

```{r methodEval, fig.cap='メソッドライブラリのメソッドに対する95\\%信頼区間のカバレッジ。各ドットは分析選択の特定セットの性能を表します。点線は名目上の性能（95\\%カバレッジ）を示します。SCCS = 自己制御症例シリーズ、GI = 胃腸、IBD = 炎症性腸疾患。', echo=FALSE, out.width='100%', fig.align='center', fig.pos='h'}
knitr::include_graphics("images/MethodValidity/methodEval.png")
```

りますが、私たちは図[18.9](https://ohdsi.github.io/TheBookOfOhdsi/MethodValidity.html#fig:methodEval)の結果から事前に情報を得て、真の効果量が95%信頼区間に含まれていない可能性が高いと結論づけなければなりません。

また、メソッドライブラリにおけるデザインの評価では、経験則に基づくキャリブレーションによって第1種の過誤と信頼区間が名目上の値に回復することが示されていますが、多くの場合、第2種の過誤が増加し、精度が低下するという代償を伴います。

## まとめ

```{block2, type='rmdsummary'}
- 手法の妥当性は、その手法の前提条件が満たされているかどうかによって決まります。
可能な場合、これらの前提条件は研究診断を用いて経験的に検証されるべきです。
- コントロール仮説、すなわち答えが既知の質問は、特定の研究デザインが真実と一致する回答を生み出すかどうかを評価するために使用されるべきです。
- 多くの場合、p値や信頼区間は、コントロール仮説を用いて測定された名目上の特性を示しません。
- これらの特性は、経験的な較正によって多くの場合、名目上の特性に復元することができます。
- 研究診断は、研究者が関心のある効果を隠したまま（-ハッキングを避けるため）分析デザインの選択を導き、プロトコルを適応させるために使用することができます。
```
